---
title: "Sentiment dashboard for computationally challenged Helge"
output: 
  flexdashboard::flex_dashboard:
    orientation: columns
    vertical_layout: fill
---

```{r setup, include=FALSE}
source("../code/install_libs.R")
```

Frequency
=======================================================================
Column {data-width=550}
-----------------------------------------------------------------------

### Noun Frequency (top 50)

```{r}
  noun_freq = read.csv("../data/noun_freq.csv")
  nounFreq_30 = noun_freq[(1:50),]
  
  ggplot(nounFreq_30, aes(x = reorder(lemma, n), y = n)) +
    geom_bar(stat = "identity") +
    coord_flip()
```

Column {data-width=550}
-----------------------------------------------------------------------

### Adjective frequency (top 50)

```{r}
  adjFreq = read.csv("../data/adj_freq.csv")
  adjFreq = adjFreq[(1:50),]
  
  ggplot(adjFreq, aes(x = reorder(lemma, n), y = n)) +
    geom_bar(stat = "identity") +
    coord_flip()
```

Frequency (2)
=======================================================================

Column {data-width=550}
-----------------------------------------------------------------------

### Nounphrase frequency (top 50)
```{r}
nounphrase = read.csv("../data/nounphrase_freq.csv")
nounphrase = nounphrase[(1:50),]
ggplot(nounphrase, aes(x=reorder(text, n), y = n)) +
  geom_bar(stat = "identity") +
  coord_flip()
```

Column {data-width=550}
-----------------------------------------------------------------------

### Entity type frequency (top 50)
```{r}
  entity_type = read.csv("../data/entity_type_freq.csv")
  entity_type = entity_type[(1:50),]
  
  ggplot(entity_type, aes(x = reorder(ent_type, n), y = n)) +
    geom_bar(stat = "identity") +
    coord_flip()
```

General sentiment
=======================================================================
```{r}
clean_df = read.csv("../data/ea_mentions_2017_2021_cleaned.csv")
  #token df
  token = data.frame(text = clean_df$x, stringsAsFactors = FALSE) %>%
    unnest_tokens(word, text)
  
  #Matching sentiment words from the 'NRC' sentiment lexicon
  senti = inner_join(token, get_sentiments("nrc")) %>%
    count(sentiment) %>%
    arrange(sentiment)
  
  senti$percent = (senti$n / sum(senti$n)) * 100
  
  #Plotting the sentiment summary
  ggplot(senti, aes(sentiment, percent)) +
    geom_bar(aes(fill = sentiment), position = 'stack', stat = 'identity') +
    ggtitle("(NRC EMO-LEX) \nEmotional Sentiment for EA \nmentions on Twitter") +
    coord_flip() +
    theme(
      plot.background = element_rect(fill = "black", colour = NA),
      panel.background = element_rect(fill = "black", colour = NA),
      legend.position = "none",
      axis.text = element_text(color = "white"),
      text = element_text(
        size = 16,
        family = "times",
        colour = "white"
      ),
    )

```