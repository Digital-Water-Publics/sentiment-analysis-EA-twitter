---
title: "Sentiment dashboard for computationally challenged Helge"
output: 
  flexdashboard::flex_dashboard:
    orientation: columns
    vertical_layout: scroll
---

```{r setup, include=FALSE}
source("../code/install_libs.R")
tweets_primary_df = readRDS("../data/tweets_primary_df_topics_best.rds")
topics = read.csv("../top_10_topic_terms_best_5.csv")
sentiment_key_word_subsets = function(df) {
  corpus = corpus(df$word)
  token_word = data.frame(text = corpus, stringsAsFactors = FALSE) %>% unnest_tokens(word, text)
  senti_word = inner_join(token_word, get_sentiments("nrc")) %>%
    count(sentiment)
  senti_word$percent = (senti_word$n / sum(senti_word$n)) * 100
  ggplot(senti_word, aes(sentiment, percent)) +
    geom_bar(aes(fill = sentiment), position = 'stack', stat = 'identity') +
    coord_flip() +
    theme(
      plot.background = element_rect(fill = "black", colour = NA),
      panel.background = element_rect(fill = "black", colour = NA),
      legend.position = "none",
      axis.text = element_text(color = "white"),
      text = element_text(
        size = 16,
        family = "times",
        colour = "white"
      ),
    )
}
plot_topic_history_freq = function(topic_n)
{
  tweets_primary_df %>%
    filter(`key_topic topic(k=5)` == topic_n) %>%
    group_by(date) %>%
    tally(sort = TRUE) %>%
    ggplot(aes(x=date, y=n)) +
    geom_line()
}


plot_general_senti_topic = function(topic_n)
{
  topic_sub = tweets_primary_df %>%
    filter(`key_topic topic(k=5)` == topic_n) %>%
    select(-c("positive","negative"))
  general_nrc_sentiment(corpus = topic_sub$word)  
}
general_nrc_sentiment = function(corpus) {

  token = data.frame(text = corpus, stringsAsFactors = FALSE) %>%
    unnest_tokens(word, text)
  
  #Matching sentiment words from the 'NRC' sentiment lexicon
  senti = inner_join(token, get_sentiments("nrc")) %>%
    count(sentiment) %>%
    filter(sentiment != "positive") %>%
    filter(sentiment != "negative") %>%
    arrange(sentiment) 
  
  senti$percent = (senti$n / sum(senti$n)) * 100
  
  #Plotting the sentiment summary
  ggplot(senti, aes(sentiment, percent)) +
    geom_bar(aes(fill = sentiment), position = 'stack', stat = 'identity') +
    ggtitle("(NRC EMO-LEX) \nEmotional Sentiment for Environment Agency \nmentions on Twitter") +
    coord_flip() +
    theme(
      plot.background = element_rect(fill = "black", colour = NA),
      panel.background = element_rect(fill = "black", colour = NA),
      legend.position = "none",
      axis.text = element_text(color = "white"),
      text = element_text(
        size = 16,
        family = "times",
        colour = "white"
      ),
    )
}
topic_frequent_emo_lex_trigger = function(topic_n)
{
  topic = tweets_primary_df %>%
    filter(`key_topic topic(k=6)` == topic_n)
  topic1_emo_lex = as.data.frame(unlist(topic$emo_lex_trigger)) %>% 
    rename(word = 1) %>% 
    count(word, sort = TRUE)
  DT::datatable(topic1_emo_lex, options = list(pageLength = 25))
}
```

Frequency
=======================================================================
Column {data-width=550}
-----------------------------------------------------------------------

### Noun Frequency (top 50)

```{r}
  noun_freq = read.csv("../data/noun_freq.csv")
  nounFreq_30 = noun_freq[(1:50),]
  
  ggplot(nounFreq_30, aes(x = reorder(lemma, n), y = n)) +
    geom_bar(stat = "identity") +
    coord_flip()
```

Column {data-width=550}
-----------------------------------------------------------------------

### Adjective frequency (top 50)

```{r}
  adjFreq = read.csv("../data/adj_freq.csv")
  adjFreq = adjFreq[(1:50),]
  
  ggplot(adjFreq, aes(x = reorder(lemma, n), y = n)) +
    geom_bar(stat = "identity") +
    coord_flip()
```

Frequency (2)
=======================================================================

Column {data-width=550}
-----------------------------------------------------------------------

### Nounphrase frequency with stop words (top 50)
```{r}
nounphrase = read.csv("../data/nounphrase_freq.csv")
nounphrase = nounphrase[(1:50),]
ggplot(nounphrase, aes(x=reorder(text, n), y = n)) +
  geom_bar(stat = "identity") +
  coord_flip()
```

Column {data-width=550}
-----------------------------------------------------------------------

### Nounphrase frequency without stop words  (top 50)
```{r}
nounphrase = read.csv("../data/nounphrase_freq_clean.csv")
nounphrase = nounphrase[(1:50),]
ggplot(nounphrase, aes(x=reorder(text, n), y = n)) +
  geom_bar(stat = "identity") +
  coord_flip()

```

Sentiment frequency
=======================================================================

Column {data-width=550}
-----------------------------------------------------------------------

### Emo_lex freq (top 50)
```{r}
  emo_lex_freq = read.csv("../data/emo_lex_freq.csv")
  emo_lex_freq = emo_lex_freq[(1:30), ]
  
  ggplot(emo_lex_freq, aes(x = reorder(tt, Freq), y = Freq)) +
    geom_bar(stat = "identity") +
    coord_flip()
```


Topic 1
=======================================================================

Row
-------------------------------------
    
### Topic historical frequency
    
```{r}
plot_topic_history_freq(topic_n = 1)
```
 
### Topic key terms
    
```{r}
df = as.data.frame(topics$Topic.1)
DT::datatable(df, options = list(
    pageLength = 25
))
``` 

Row
-------------------------------------
    
### Topic general sentiment
    
```{r}
plot_general_senti_topic(topic_n = 1)
```
    
### Topic emo_lex_frequency

```{r}
topic_frequent_emo_lex_trigger(topic_n = 1)
```


Topic 2
=======================================================================

Row
-------------------------------------
    
### Topic historical frequency
    
```{r}
plot_topic_history_freq(topic_n = 2)
```
 
### Topic key terms
    
```{r}
df = as.data.frame(topics$Topic.2)
DT::datatable(df, options = list(
    pageLength = 25
))
``` 

Row
-------------------------------------
    
### Topic general sentiment
    
```{r}
plot_general_senti_topic(topic_n = 2)
```
    
### Topic emo_lex_frequency

```{r}
topic_frequent_emo_lex_trigger(topic_n = 2)
```

Topic 3
=======================================================================

Row
-------------------------------------
    
### Topic historical frequency
    
```{r}
plot_topic_history_freq(topic_n = 3)
```
 
### Topic key terms
    
```{r}
df = as.data.frame(topics$Topic.3)
DT::datatable(df, options = list(
    pageLength = 25
))
``` 

Row
-------------------------------------
    
### Topic general sentiment
    
```{r}
plot_general_senti_topic(topic_n = 3)
```
    
### Topic emo_lex_frequency

```{r}
topic_frequent_emo_lex_trigger(topic_n = 3)
```

Topic 4
=======================================================================

Row
-------------------------------------
    
### Topic historical frequency
    
```{r}
plot_topic_history_freq(topic_n = 4)
```
 
### Topic key terms
    
```{r}
df = as.data.frame(topics$Topic.4)
DT::datatable(df, options = list(
    pageLength = 25
))
``` 

Row
-------------------------------------
    
### Topic general sentiment
    
```{r}
plot_general_senti_topic(topic_n = 4)
```
    
### Topic emo_lex_frequency

```{r}
topic_frequent_emo_lex_trigger(topic_n = 4)
```

Topic 5
=======================================================================

Row
-------------------------------------
    
### Topic historical frequency
    
```{r}
plot_topic_history_freq(topic_n = 5)
```
 
### Topic key terms
    
```{r}
df = as.data.frame(topics$Topic.5)
DT::datatable(df, options = list(
    pageLength = 25
))
``` 

Row
-------------------------------------
    
### Topic general sentiment
    
```{r}
plot_general_senti_topic(topic_n = 5)
```
    
### Topic emo_lex_frequency

```{r}
topic_frequent_emo_lex_trigger(topic_n = 5)
```

Flood subset
=======================================================================

    
### Tweets sample
    
```{r}
flood_subset = filter(
  tweets_primary_df,
  grepl('\\bflood\\b', word) |
    grepl('\\bheavy\\b.*\\brain\\b', word)
)
sample_flood = flood_subset %>% select(word)
DT::datatable(sample_flood, options = list(
    pageLength = 25
))

```


### Sentiment
    
```{r}
flood_subset$word = gsub(" flood", "", flood_subset$word)
flood_subset$word = gsub(" heavy rain", "", flood_subset$word)
sentiment_key_word_subsets(df = flood_subset)
``` 

Pollution subset
=======================================================================
    
### Tweets sample
    
```{r}
pollution_subset = filter(
  tweets_primary_df,
  grepl('\\bsewage\\b', word) |
    grepl('\\bpollution\\b', word) |
    grepl('\\bpollute\\b', word) |
    grepl('\\bpolluting\\b', word) |
    grepl('\\bpolluter\\b', word) |
    grepl('\\bpolluters\\b', word) |
    grepl('\\bwastewater\\b', word) |
    grepl('\\bwaste\\b.*\\bwater\\b', word) 
)
sample_pollution = pollution_subset %>% select(word)
DT::datatable(sample_pollution, options = list(
    pageLength = 25
))

```
 

### Sentiment
    
```{r}
pollution_subset$word = gsub(" sewage", "", pollution_subset$word)
pollution_subset$word = gsub(" pollution", "", pollution_subset$word)
pollution_subset$word = gsub(" pollute", "", pollution_subset$word)
pollution_subset$word = gsub(" polluters", "", pollution_subset$word)
pollution_subset$word = gsub(" polluter", "", pollution_subset$word)
pollution_subset$word = gsub(" polluting", "", pollution_subset$word)
pollution_subset$word = gsub(" waste", "", pollution_subset$word)
sentiment_key_word_subsets(df = pollution_subset)
``` 

water industry subset
=======================================================================

    
### Tweets sample
    
```{r}
water_indsustry_subset = filter(
  tweets_primary_df,
  grepl('\\bwater\\b.*\\bcompany\\b', word) |
    grepl('\\bwater\\b.*\\bcompanies\\b', word) |
    grepl('\\bwater\\b.*\\bindustry\\b', word) |
    grepl('\\bwater\\b.*\\bindustries\\b', word) |
    grepl('\\bwater\\b.*\\butility\\b', word) |
    grepl('\\bwater\\b.*\\butilities\\b', word)
)
sample_water_indsustry = water_indsustry_subset %>% select(word)
DT::datatable(sample_water_indsustry, options = list(
    pageLength = 25
))

```
 

### Sentiment
    
```{r}
water_indsustry_subset$word = gsub(" water company", "", water_indsustry_subset$word)
water_indsustry_subset$word = gsub(" water companies", "", water_indsustry_subset$word)
water_indsustry_subset$word = gsub(" water industry", "", water_indsustry_subset$word)
water_indsustry_subset$word = gsub(" water industries", "", water_indsustry_subset$word)
water_indsustry_subset$word = gsub(" water utility", "", water_indsustry_subset$word)
water_indsustry_subset$word = gsub(" water utilites", "", water_indsustry_subset$word)

sentiment_key_word_subsets(df = water_indsustry_subset)
``` 

